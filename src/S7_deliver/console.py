"""Console and file output."""

import json
import textwrap
from datetime import datetime
from pathlib import Path

from ..models import NewsItem


def to_console(items: list[NewsItem], stats: dict | None = None) -> None:
    """Print formatted output to console."""
    today = datetime.now().strftime("%Y-%m-%d")

    print()
    print("=" * 80)
    print(f"  ScholarPipe | {today}")
    print("=" * 80)
    print()

    if not items:
        print("  (今日无推荐内容)")
        print()
    else:
        for i, item in enumerate(items, 1):
            # Use semantic score for display
            sem_str = f"{item.semantic_score:.2f}" if item.semantic_score else "-"
            vip_tag = ""
            if item.is_vip and item.vip_keywords:
                vip_tag = f" [VIP: {', '.join(item.vip_keywords)}]"
            elif item.is_vip:
                vip_tag = " [VIP]"

            print("-" * 80)
            print(f"[{i}] {item.title}{vip_tag}")
            print(f"    来源: {item.source_name} | 相关度: {sem_str}")

            if item.authors:
                authors_str = ", ".join(item.authors[:3])
                if len(item.authors) > 3:
                    authors_str += f" 等 {len(item.authors)} 人"
                print(f"    作者: {authors_str}")

            print()
            summary = item.summary if item.summary else "(无摘要)"
            wrapped = textwrap.fill(summary, width=76, initial_indent="    ", subsequent_indent="    ")
            print(wrapped)
            print()
            print(f"    {item.link}")
            print("-" * 80)
            print()

    if stats:
        print("=" * 80)
        total = stats.get('total', 0)
        after_dedup = stats.get('after_dedup', 0)
        after_filter = stats.get('after_filter', 0)

        print(f"  统计: 抓取 {total} -> 去重 {after_dedup} -> 过滤 {after_filter}")
        print("=" * 80)


def to_json(items: list[NewsItem], path: str) -> None:
    """Export items to JSON file."""
    data = [item.model_dump() for item in items]

    Path(path).parent.mkdir(parents=True, exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2, default=str)


def to_markdown(items: list[NewsItem]) -> str:
    """Generate markdown formatted output."""
    today = datetime.now().strftime("%Y-%m-%d")
    lines = [
        f"# ScholarPipe 学术日报",
        f"",
        f"**日期**: {today}  ",
        f"**篇数**: {len(items)}",
        f"",
        f"---",
        f"",
    ]

    for i, item in enumerate(items, 1):
        sem_str = f"{item.semantic_score:.2f}" if item.semantic_score else "-"
        vip_tag = ""
        if item.is_vip and item.vip_keywords:
            vip_tag = f" [VIP: {', '.join(item.vip_keywords)}]"
        elif item.is_vip:
            vip_tag = " [VIP]"

        lines.append(f"## {i}. {item.title}{vip_tag}")
        lines.append(f"")
        lines.append(f"**来源**: {item.source_name} | **相关度**: {sem_str}")

        if item.authors:
            authors_str = ", ".join(item.authors[:5])
            if len(item.authors) > 5:
                authors_str += f" 等 {len(item.authors)} 人"
            lines.append(f"**作者**: {authors_str}")

        lines.append(f"")
        lines.append(f"{item.summary if item.summary else (item.content[:200] + '...' if len(item.content) > 200 else item.content) or '(无摘要)'}")
        lines.append(f"")
        lines.append(f"[阅读原文]({item.link})")
        lines.append(f"")
        lines.append(f"---")
        lines.append(f"")

    lines.append(f"")
    lines.append(f"*Generated by ScholarPipe*")

    return "\n".join(lines)
